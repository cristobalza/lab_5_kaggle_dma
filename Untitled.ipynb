{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "# import calendar\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "from pylab import rcParams\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier,  AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, learning_curve, cross_validate, train_test_split, KFold\n",
    "# from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These 4 functions are essentially the same code but the only difference is the `scoring` \n",
    "# parameter of the cross_validate func.\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring\n",
    "def accuracy_compare(X, target, models, cv):\n",
    "    # Step 1 : Create an empty DataFrame and a row_index counting variable\n",
    "    model_df = pd.DataFrame()\n",
    "    row_index_count = 0\n",
    "    # Iterate through each Machine Learning Model\n",
    "    for each_model in models:\n",
    "        # With the row index, input the name of the current Model\n",
    "        model_df.loc[row_index_count, 'Model Name'] = each_model.__class__.__name__\n",
    "        # Step 2 : Create a Cross-Validated Object using `cross_validate` from Sklearn \n",
    "        cv_results = cross_validate(\n",
    "            each_model,\n",
    "            X,\n",
    "            target,\n",
    "            cv=cv,\n",
    "            scoring='accuracy',\n",
    "            return_train_score=True,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        # Input the Accuracy of prediction of each column\n",
    "        model_df.loc[row_index_count, 'Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "        model_df.loc[row_index_count, 'Test Accuracy Mean'] = cv_results['test_score'].mean()\n",
    "        row_index_count = row_index_count + 1\n",
    "\n",
    "    # Step 3 : sort the DataFrame values by the Test Accuracy Mean  \n",
    "    model_df.sort_values(by=['Test Accuracy Mean'],\n",
    "                            ascending=False,\n",
    "                            inplace=True)\n",
    "\n",
    "    return model_df.style.background_gradient(cmap='Greens')\n",
    "\n",
    "def f1_compare(X, target, models, cv):\n",
    "    # Step 1 : Create an empty DataFrame and a row_index counting variable\n",
    "    model_df = pd.DataFrame()\n",
    "    row_index_count = 0\n",
    "    # Iterate through each Machine Learning Model\n",
    "    for each_model in models:\n",
    "        # With the row index, input the name of the current Model\n",
    "        model_df.loc[row_index_count, 'Model Name'] = each_model.__class__.__name__\n",
    "        # Step 2 : Create a Cross-Validated Object using `cross_validate` from Sklearn \n",
    "        cv_results = cross_validate(\n",
    "            each_model,\n",
    "            X,\n",
    "            target,\n",
    "            cv=cv,\n",
    "            scoring='f1',\n",
    "            return_train_score=True,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        # Input the Accuracy of prediction of each column\n",
    "        model_df.loc[row_index_count, 'Train F1 Score Mean'] = cv_results['train_score'].mean()\n",
    "        model_df.loc[row_index_count, 'Test F1 Score Mean'] = cv_results['test_score'].mean()\n",
    "\n",
    "        row_index_count = row_index_count + 1\n",
    "\n",
    "    # Step 3 : sort the DataFrame values by the Test Accuracy Mean  \n",
    "    model_df.sort_values(by=['Test F1 Score Mean'],\n",
    "                            ascending=False,\n",
    "                            inplace=True)\n",
    "\n",
    "    return model_df.style.background_gradient(cmap='Oranges')\n",
    "def precision_compare(X, target, models, cv):\n",
    "    # Step 1 : Create an empty DataFrame and a row_index counting variable\n",
    "    model_df = pd.DataFrame()\n",
    "    row_index_count = 0\n",
    "    # Iterate through each Machine Learning Model\n",
    "    for each_model in models:\n",
    "        # With the row index, input the name of the current Model\n",
    "        model_df.loc[row_index_count, 'Model Name'] = each_model.__class__.__name__\n",
    "        # Step 2 : Create a Cross-Validated Object using `cross_validate` from Sklearn \n",
    "        cv_results = cross_validate(\n",
    "            each_model,\n",
    "            X,\n",
    "            target,\n",
    "            cv=cv,\n",
    "            scoring='precision',\n",
    "            return_train_score=True,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        # Input the Accuracy of prediction of each column\n",
    "        model_df.loc[row_index_count, 'Train Precision Mean'] = cv_results['train_score'].mean()\n",
    "        model_df.loc[row_index_count, 'Test Precision Mean'] = cv_results['test_score'].mean()\n",
    "\n",
    "        row_index_count = row_index_count + 1\n",
    "\n",
    "    # Step 3 : sort the DataFrame values by the Test Accuracy Mean  \n",
    "    model_df.sort_values(by=['Test Precision Mean'],\n",
    "                            ascending=False,\n",
    "                            inplace=True)\n",
    "\n",
    "    return model_df.style.background_gradient(cmap='Blues')\n",
    "\n",
    "def recall_compare(X, target, models, cv):\n",
    "    # Step 1 : Create an empty DataFrame and a row_index counting variable\n",
    "    model_df = pd.DataFrame()\n",
    "    row_index_count = 0\n",
    "    # Iterate through each Machine Learning Model\n",
    "    for each_model in models:\n",
    "        # With the row index, input the name of the current Model\n",
    "        model_df.loc[row_index_count, 'Model Name'] = each_model.__class__.__name__\n",
    "        # Step 2 : Create a Cross-Validated Object using `cross_validate` from Sklearn \n",
    "        cv_results = cross_validate(\n",
    "            each_model,\n",
    "            X,\n",
    "            target,\n",
    "            cv=cv,\n",
    "            scoring='recall',\n",
    "            return_train_score=True,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        # Input the Accuracy of prediction of each column\n",
    "        model_df.loc[row_index_count, 'Train Recall Mean'] = cv_results['train_score'].mean()\n",
    "        model_df.loc[row_index_count, 'Test Recall Mean'] = cv_results['test_score'].mean()\n",
    "\n",
    "        row_index_count = row_index_count + 1\n",
    "\n",
    "    # Step 3 : sort the DataFrame values by the Test Accuracy Mean  \n",
    "    model_df.sort_values(by=['Test Recall Mean'],\n",
    "                            ascending=False,\n",
    "                            inplace=True)\n",
    "\n",
    "    return model_df.style.background_gradient(cmap='Purples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristobalza/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1309, 12)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "target = train_df['Survived']\n",
    "\n",
    "train_lenght = len(train_df)\n",
    "passengers_ID_test = test_df['PassengerId']\n",
    "\n",
    "entire_dataset =  pd.concat(objs=[train_df, test_df], axis=0).reset_index(drop=True)\n",
    "entire_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristobalza/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/cristobalza/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Adding a Family_Size feature\n",
    "entire_dataset['Family_Size'] = 1\n",
    "entire_dataset['Family_Size'] = entire_dataset['Parch']+entire_dataset['SibSp'] + 1\n",
    "\n",
    "# Adding a Alone feature\n",
    "entire_dataset['Alone'] = 0\n",
    "alone_func = lambda x : 1 if x == 1 else 0\n",
    "entire_dataset['Alone'] = entire_dataset['Family_Size'].apply(alone_func)\n",
    "\n",
    "# Adding a Small_Family feature\n",
    "entire_dataset['Small_Family'] = 0\n",
    "small_fam_func = lambda x : 1 if 2 <= x <= 3 else 0\n",
    "entire_dataset['Small_Family'] = entire_dataset['Family_Size'].apply(small_fam_func)\n",
    "\n",
    "# Adding a Medium_Family feature\n",
    "entire_dataset['Medium_Family'] = 0\n",
    "medium_fam_func = lambda x : 1 if 4 <= x <= 6 else 0\n",
    "entire_dataset['Medium_Family'] = entire_dataset['Family_Size'].apply(medium_fam_func)\n",
    "\n",
    "# Adding a Large_Family feature\n",
    "entire_dataset['Large_Family'] = 0\n",
    "large_fam_func = lambda x : 1 if 7 <= x else 0\n",
    "entire_dataset['Large_Family'] = entire_dataset['Family_Size'].apply(large_fam_func)\n",
    "\n",
    "#Embarked\n",
    "entire_dataset['Embarked'].fillna('S', inplace = True)\n",
    "\n",
    "# Cabin_Multiple\n",
    "cabin_func = lambda x : 0 if pd.isna(x) else len(x.split(' '))\n",
    "entire_dataset['Cabin_Multiple'] = entire_dataset['Cabin'].apply(cabin_func)\n",
    "\n",
    "# The feature with most missing values is Cabin with U for Unknown\n",
    "entire_dataset['Cabin'].fillna('U', inplace=True)\n",
    "\n",
    "# Cabin_Section\n",
    "cabin_func_2 = lambda x : str(x)[0]\n",
    "entire_dataset['Cabin_Section'] = entire_dataset['Cabin'].apply(cabin_func_2)\n",
    "\n",
    "# Age\n",
    "age_mean = entire_dataset['Age'].mean()\n",
    "age_std = entire_dataset['Age'].std()\n",
    "age_null_count = entire_dataset['Age'].isnull().sum()\n",
    "\n",
    "# Return random integers from `low` (inclusive) to `high` (exclusive).\n",
    "age_null_random = np.random.randint(age_mean - age_std, age_mean + age_std, size=age_null_count)\n",
    "# Choose the rows that are null and fill them up\n",
    "entire_dataset['Age'][np.isnan(entire_dataset['Age'])] = age_null_random\n",
    "entire_dataset['Age'] = entire_dataset['Age'].astype(int)\n",
    "\n",
    "# Name_Title\n",
    "title_func = lambda x : x.split(',')[1].split('.')[0].strip()\n",
    "entire_dataset['Name_Title'] = entire_dataset['Name'].apply(title_func)\n",
    "\n",
    "#Social_Title\n",
    "entire_dataset['Social_Title'] = entire_dataset['Name_Title']\n",
    "entire_dataset['Social_Title'] = entire_dataset['Social_Title'].replace(['Sir', 'Jonkheer', 'Rev', 'Col', 'Lady', 'Major', 'Don', 'the Countess'], 'Royalty')\n",
    "entire_dataset['Social_Title'] = entire_dataset['Social_Title'].replace(['Dr', 'Capt', 'Master'], 'Professional')\n",
    "entire_dataset['Social_Title'] = entire_dataset['Social_Title'].replace(['Mme', 'Mrs', 'Dona'], 'Wife')\n",
    "entire_dataset['Social_Title'] = entire_dataset['Social_Title'].replace(['Mr', 'Ms', 'Miss', 'Mlle'], 'Ordinary')\n",
    "\n",
    "#Age_Categorical\n",
    "entire_dataset['Age_Categorical'] = pd.cut(entire_dataset['Age'], 6)\n",
    "entire_dataset['Age_Categorical'] = entire_dataset['Age_Categorical'].astype(object)\n",
    "\n",
    "fare_mean = entire_dataset['Fare'].mean()\n",
    "fare_std = entire_dataset['Fare'].std()\n",
    "fare_null_count = entire_dataset['Fare'].isnull().sum()\n",
    "# Return random integers from `low` (inclusive) to `high` (exclusive).\n",
    "fare_null_random = np.random.randint(fare_mean - fare_std, fare_mean + fare_std, size=fare_null_count)\n",
    "# Choose the rows that are null and fill them up\n",
    "entire_dataset['Fare'][np.isnan(entire_dataset['Fare'])] = fare_null_random\n",
    "entire_dataset['Fare'] = entire_dataset['Fare'].astype(float)\n",
    "\n",
    "#Fare_Categorical\n",
    "entire_dataset['Fare_Categorical'] = pd.qcut(entire_dataset['Fare'], 4)\n",
    "entire_dataset['Fare_Categorical'] = entire_dataset['Fare_Categorical'].astype(object)\n",
    "\n",
    "entire_dataset.drop(columns=['Survived', 'PassengerId', 'Name'], inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'Fare',\n",
       " 'Parch',\n",
       " 'Pclass',\n",
       " 'SibSp',\n",
       " 'Family_Size',\n",
       " 'Alone',\n",
       " 'Small_Family',\n",
       " 'Medium_Family',\n",
       " 'Large_Family',\n",
       " 'Cabin_Multiple']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = entire_dataset\n",
    "# Check for NON Categorical features\n",
    "non_categorical_feature_mask = entire_dataset.dtypes!=object\n",
    "# Filter non categorical columns using mask and turn it into a list\n",
    "non_categorical_features = entire_dataset.columns[non_categorical_feature_mask].tolist()\n",
    "display(len(non_categorical_features))\n",
    "non_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Cabin',\n",
       " 'Embarked',\n",
       " 'Sex',\n",
       " 'Ticket',\n",
       " 'Cabin_Section',\n",
       " 'Name_Title',\n",
       " 'Social_Title',\n",
       " 'Age_Categorical',\n",
       " 'Fare_Categorical']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Categorical features\n",
    "categorical_feature_mask = entire_dataset.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = entire_dataset.columns[categorical_feature_mask].tolist()\n",
    "display(len(categorical_cols))\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristobalza/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/cristobalza/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1309, 1173)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "# Since not all features are categorical features,  `make_column_transformer` will only\n",
    "# one hot encode the categorical feature and standarized the non-categorical features.\n",
    "column_trans = make_column_transformer(\n",
    "    (StandardScaler(), non_categorical_features),\n",
    "    (OneHotEncoder(sparse=False), categorical_cols)\n",
    ")\n",
    "\n",
    "entire_dataset_custom = column_trans.fit_transform(entire_dataset)\n",
    "entire_dataset_custom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = entire_dataset_custom[:train_lenght]\n",
    "x_test = entire_dataset_custom[train_lenght:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (891, 1173)\n",
      "X_test shape: (418, 1173)\n",
      "y shape: (891,)\n"
     ]
    }
   ],
   "source": [
    "target = train_df['Survived']\n",
    "print(f'X_train shape: {x_train.shape}')\n",
    "# print(f'y shape: {y.shape}')\n",
    "print(f'X_test shape: {x_test.shape}')\n",
    "print(f'y shape: {target.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(10, shuffle=True)\n",
    "\n",
    "naive = GaussianNB()\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "gradient = GradientBoostingClassifier()\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "\n",
    "extra_dt = ExtraTreesClassifier()\n",
    "\n",
    "models = [naive, knn,  dtree, rf, svc, lr, gradient, ada, extra_dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_ab69a150_0840_11eb_b896_acde48001122row0_col1 {\n",
       "            background-color:  #a2d99c;\n",
       "            color:  #000000;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row0_col2 {\n",
       "            background-color:  #00441b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row1_col1 {\n",
       "            background-color:  #58b668;\n",
       "            color:  #000000;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row1_col2 {\n",
       "            background-color:  #00471c;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row2_col1 {\n",
       "            background-color:  #8ace88;\n",
       "            color:  #000000;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row2_col2 {\n",
       "            background-color:  #004c1e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row3_col1 {\n",
       "            background-color:  #00441b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row3_col2 {\n",
       "            background-color:  #004d1f;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row4_col1 {\n",
       "            background-color:  #00441b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row4_col2 {\n",
       "            background-color:  #004e1f;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row5_col1 {\n",
       "            background-color:  #81ca81;\n",
       "            color:  #000000;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row5_col2 {\n",
       "            background-color:  #005622;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row6_col1 {\n",
       "            background-color:  #005e26;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row6_col2 {\n",
       "            background-color:  #005b25;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row7_col1 {\n",
       "            background-color:  #f7fcf5;\n",
       "            color:  #000000;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row7_col2 {\n",
       "            background-color:  #117b38;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row8_col1 {\n",
       "            background-color:  #19833e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ab69a150_0840_11eb_b896_acde48001122row8_col2 {\n",
       "            background-color:  #f7fcf5;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_ab69a150_0840_11eb_b896_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model Name</th>        <th class=\"col_heading level0 col1\" >Train Accuracy Mean</th>        <th class=\"col_heading level0 col2\" >Test Accuracy Mean</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ab69a150_0840_11eb_b896_acde48001122level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row0_col0\" class=\"data row0 col0\" >KNeighborsClassifier</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row0_col1\" class=\"data row0 col1\" >0.854096</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row0_col2\" class=\"data row0 col2\" >0.830381</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ab69a150_0840_11eb_b896_acde48001122level0_row1\" class=\"row_heading level0 row1\" >5</th>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row1_col0\" class=\"data row1 col0\" >LogisticRegression</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row1_col1\" class=\"data row1 col1\" >0.89924</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row1_col2\" class=\"data row1 col2\" >0.827023</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ab69a150_0840_11eb_b896_acde48001122level0_row2\" class=\"row_heading level0 row2\" >6</th>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row2_col0\" class=\"data row2 col0\" >GradientBoostingClassifier</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row2_col1\" class=\"data row2 col1\" >0.869686</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row2_col2\" class=\"data row2 col2\" >0.821531</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ab69a150_0840_11eb_b896_acde48001122level0_row3\" class=\"row_heading level0 row3\" >2</th>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row3_col0\" class=\"data row3 col0\" >DecisionTreeClassifier</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row3_col1\" class=\"data row3 col1\" >1</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row3_col2\" class=\"data row3 col2\" >0.82047</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ab69a150_0840_11eb_b896_acde48001122level0_row4\" class=\"row_heading level0 row4\" >8</th>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row4_col0\" class=\"data row4 col0\" >ExtraTreesClassifier</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row4_col2\" class=\"data row4 col2\" >0.818211</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ab69a150_0840_11eb_b896_acde48001122level0_row5\" class=\"row_heading level0 row5\" >7</th>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row5_col0\" class=\"data row5 col0\" >AdaBoostClassifier</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row5_col1\" class=\"data row5 col1\" >0.874674</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row5_col2\" class=\"data row5 col2\" >0.809322</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ab69a150_0840_11eb_b896_acde48001122level0_row6\" class=\"row_heading level0 row6\" >3</th>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row6_col0\" class=\"data row6 col0\" >RandomForestClassifier</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row6_col1\" class=\"data row6 col1\" >0.981668</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row6_col2\" class=\"data row6 col2\" >0.804714</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ab69a150_0840_11eb_b896_acde48001122level0_row7\" class=\"row_heading level0 row7\" >4</th>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row7_col0\" class=\"data row7 col0\" >SVC</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row7_col1\" class=\"data row7 col1\" >0.767301</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row7_col2\" class=\"data row7 col2\" >0.763138</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ab69a150_0840_11eb_b896_acde48001122level0_row8\" class=\"row_heading level0 row8\" >0</th>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row8_col0\" class=\"data row8 col0\" >GaussianNB</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row8_col1\" class=\"data row8 col1\" >0.949494</td>\n",
       "                        <td id=\"T_ab69a150_0840_11eb_b896_acde48001122row8_col2\" class=\"data row8 col2\" >0.468165</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe07e3afa10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_b72d4dc0_0840_11eb_b896_acde48001122row0_col1 {\n",
       "            background-color:  #fc8937;\n",
       "            color:  #000000;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row0_col2 {\n",
       "            background-color:  #7f2704;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row1_col1 {\n",
       "            background-color:  #ef6612;\n",
       "            color:  #000000;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row1_col2 {\n",
       "            background-color:  #842904;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row2_col1 {\n",
       "            background-color:  #7f2704;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row2_col2 {\n",
       "            background-color:  #9c3203;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row3_col1 {\n",
       "            background-color:  #f77b28;\n",
       "            color:  #000000;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row3_col2 {\n",
       "            background-color:  #a43503;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row4_col1 {\n",
       "            background-color:  #942f03;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row4_col2 {\n",
       "            background-color:  #ae3903;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row5_col1 {\n",
       "            background-color:  #fd9547;\n",
       "            color:  #000000;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row5_col2 {\n",
       "            background-color:  #bb3d02;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row6_col1 {\n",
       "            background-color:  #7f2704;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row6_col2 {\n",
       "            background-color:  #bb3d02;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row7_col1 {\n",
       "            background-color:  #fff5eb;\n",
       "            color:  #000000;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row7_col2 {\n",
       "            background-color:  #fdd0a2;\n",
       "            color:  #000000;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row8_col1 {\n",
       "            background-color:  #b63c02;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_b72d4dc0_0840_11eb_b896_acde48001122row8_col2 {\n",
       "            background-color:  #fff5eb;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_b72d4dc0_0840_11eb_b896_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model Name</th>        <th class=\"col_heading level0 col1\" >Train F1 Score Mean</th>        <th class=\"col_heading level0 col2\" >Test F1 Score Mean</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b72d4dc0_0840_11eb_b896_acde48001122level0_row0\" class=\"row_heading level0 row0\" >6</th>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row0_col0\" class=\"data row0 col0\" >GradientBoostingClassifier</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row0_col1\" class=\"data row0 col1\" >0.820763</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row0_col2\" class=\"data row0 col2\" >0.774035</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b72d4dc0_0840_11eb_b896_acde48001122level0_row1\" class=\"row_heading level0 row1\" >5</th>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row1_col0\" class=\"data row1 col0\" >LogisticRegression</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row1_col1\" class=\"data row1 col1\" >0.86534</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row1_col2\" class=\"data row1 col2\" >0.770524</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b72d4dc0_0840_11eb_b896_acde48001122level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row2_col0\" class=\"data row2 col0\" >DecisionTreeClassifier</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row2_col2\" class=\"data row2 col2\" >0.753219</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b72d4dc0_0840_11eb_b896_acde48001122level0_row3\" class=\"row_heading level0 row3\" >7</th>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row3_col0\" class=\"data row3 col0\" >AdaBoostClassifier</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row3_col1\" class=\"data row3 col1\" >0.838221</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row3_col2\" class=\"data row3 col2\" >0.749037</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b72d4dc0_0840_11eb_b896_acde48001122level0_row4\" class=\"row_heading level0 row4\" >3</th>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row4_col0\" class=\"data row4 col0\" >RandomForestClassifier</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row4_col1\" class=\"data row4 col1\" >0.974766</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row4_col2\" class=\"data row4 col2\" >0.742901</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b72d4dc0_0840_11eb_b896_acde48001122level0_row5\" class=\"row_heading level0 row5\" >1</th>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row5_col0\" class=\"data row5 col0\" >KNeighborsClassifier</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row5_col1\" class=\"data row5 col1\" >0.804503</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row5_col2\" class=\"data row5 col2\" >0.736182</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b72d4dc0_0840_11eb_b896_acde48001122level0_row6\" class=\"row_heading level0 row6\" >8</th>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row6_col0\" class=\"data row6 col0\" >ExtraTreesClassifier</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row6_col1\" class=\"data row6 col1\" >1</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row6_col2\" class=\"data row6 col2\" >0.736097</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b72d4dc0_0840_11eb_b896_acde48001122level0_row7\" class=\"row_heading level0 row7\" >4</th>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row7_col0\" class=\"data row7 col0\" >SVC</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row7_col1\" class=\"data row7 col1\" >0.630486</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row7_col2\" class=\"data row7 col2\" >0.614728</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b72d4dc0_0840_11eb_b896_acde48001122level0_row8\" class=\"row_heading level0 row8\" >0</th>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row8_col0\" class=\"data row8 col0\" >GaussianNB</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row8_col1\" class=\"data row8 col1\" >0.938294</td>\n",
       "                        <td id=\"T_b72d4dc0_0840_11eb_b896_acde48001122row8_col2\" class=\"data row8 col2\" >0.560845</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe07e3b9410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_c2e3a498_0840_11eb_b896_acde48001122row0_col1 {\n",
       "            background-color:  #083674;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row0_col2 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row1_col1 {\n",
       "            background-color:  #e8f1fa;\n",
       "            color:  #000000;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row1_col2 {\n",
       "            background-color:  #083573;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row2_col1 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row2_col2 {\n",
       "            background-color:  #083674;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row3_col1 {\n",
       "            background-color:  #d0e2f2;\n",
       "            color:  #000000;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row3_col2 {\n",
       "            background-color:  #083776;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row4_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row4_col2 {\n",
       "            background-color:  #083877;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row5_col1 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row5_col2 {\n",
       "            background-color:  #083b7c;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row6_col1 {\n",
       "            background-color:  #e2edf8;\n",
       "            color:  #000000;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row6_col2 {\n",
       "            background-color:  #084082;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row7_col1 {\n",
       "            background-color:  #9dcae1;\n",
       "            color:  #000000;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row7_col2 {\n",
       "            background-color:  #084488;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row8_col1 {\n",
       "            background-color:  #a4cce3;\n",
       "            color:  #000000;\n",
       "        }    #T_c2e3a498_0840_11eb_b896_acde48001122row8_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_c2e3a498_0840_11eb_b896_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model Name</th>        <th class=\"col_heading level0 col1\" >Train Precision Mean</th>        <th class=\"col_heading level0 col2\" >Test Precision Mean</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c2e3a498_0840_11eb_b896_acde48001122level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row0_col0\" class=\"data row0 col0\" >RandomForestClassifier</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row0_col1\" class=\"data row0 col1\" >0.995278</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row0_col2\" class=\"data row0 col2\" >0.810006</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2e3a498_0840_11eb_b896_acde48001122level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row1_col0\" class=\"data row1 col0\" >KNeighborsClassifier</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row1_col1\" class=\"data row1 col1\" >0.832375</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row1_col2\" class=\"data row1 col2\" >0.802158</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2e3a498_0840_11eb_b896_acde48001122level0_row2\" class=\"row_heading level0 row2\" >8</th>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row2_col0\" class=\"data row2 col0\" >ExtraTreesClassifier</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row2_col2\" class=\"data row2 col2\" >0.79922</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2e3a498_0840_11eb_b896_acde48001122level0_row3\" class=\"row_heading level0 row3\" >6</th>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row3_col0\" class=\"data row3 col0\" >GradientBoostingClassifier</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row3_col1\" class=\"data row3 col1\" >0.853946</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row3_col2\" class=\"data row3 col2\" >0.798706</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2e3a498_0840_11eb_b896_acde48001122level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row4_col0\" class=\"data row4 col0\" >SVC</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row4_col1\" class=\"data row4 col1\" >0.818293</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row4_col2\" class=\"data row4 col2\" >0.79753</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2e3a498_0840_11eb_b896_acde48001122level0_row5\" class=\"row_heading level0 row5\" >2</th>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row5_col0\" class=\"data row5 col0\" >DecisionTreeClassifier</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row5_col1\" class=\"data row5 col1\" >1</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row5_col2\" class=\"data row5 col2\" >0.792173</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2e3a498_0840_11eb_b896_acde48001122level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row6_col0\" class=\"data row6 col0\" >AdaBoostClassifier</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row6_col1\" class=\"data row6 col1\" >0.838132</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row6_col2\" class=\"data row6 col2\" >0.78645</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2e3a498_0840_11eb_b896_acde48001122level0_row7\" class=\"row_heading level0 row7\" >5</th>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row7_col0\" class=\"data row7 col0\" >LogisticRegression</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row7_col1\" class=\"data row7 col1\" >0.88644</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row7_col2\" class=\"data row7 col2\" >0.779805</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2e3a498_0840_11eb_b896_acde48001122level0_row8\" class=\"row_heading level0 row8\" >0</th>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row8_col0\" class=\"data row8 col0\" >GaussianNB</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row8_col1\" class=\"data row8 col1\" >0.882981</td>\n",
       "                        <td id=\"T_c2e3a498_0840_11eb_b896_acde48001122row8_col2\" class=\"data row8 col2\" >0.414398</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe07e50d510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_ce58bbce_0840_11eb_b896_acde48001122row0_col1 {\n",
       "            background-color:  #3f007d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row0_col2 {\n",
       "            background-color:  #3f007d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row1_col1 {\n",
       "            background-color:  #7567af;\n",
       "            color:  #000000;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row1_col2 {\n",
       "            background-color:  #776ab0;\n",
       "            color:  #000000;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row2_col1 {\n",
       "            background-color:  #7b72b4;\n",
       "            color:  #000000;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row2_col2 {\n",
       "            background-color:  #7f7bb9;\n",
       "            color:  #000000;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row3_col1 {\n",
       "            background-color:  #9490c3;\n",
       "            color:  #000000;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row3_col2 {\n",
       "            background-color:  #8683bd;\n",
       "            color:  #000000;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row4_col1 {\n",
       "            background-color:  #8e8ac0;\n",
       "            color:  #000000;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row4_col2 {\n",
       "            background-color:  #8986be;\n",
       "            color:  #000000;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row5_col1 {\n",
       "            background-color:  #3f007d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row5_col2 {\n",
       "            background-color:  #928fc3;\n",
       "            color:  #000000;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row6_col1 {\n",
       "            background-color:  #4c1888;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row6_col2 {\n",
       "            background-color:  #9995c6;\n",
       "            color:  #000000;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row7_col1 {\n",
       "            background-color:  #3f007d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row7_col2 {\n",
       "            background-color:  #9995c6;\n",
       "            color:  #000000;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row8_col1 {\n",
       "            background-color:  #fcfbfd;\n",
       "            color:  #000000;\n",
       "        }    #T_ce58bbce_0840_11eb_b896_acde48001122row8_col2 {\n",
       "            background-color:  #fcfbfd;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_ce58bbce_0840_11eb_b896_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model Name</th>        <th class=\"col_heading level0 col1\" >Train Recall Mean</th>        <th class=\"col_heading level0 col2\" >Test Recall Mean</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ce58bbce_0840_11eb_b896_acde48001122level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row0_col0\" class=\"data row0 col0\" >GaussianNB</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row0_col2\" class=\"data row0 col2\" >0.885882</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce58bbce_0840_11eb_b896_acde48001122level0_row1\" class=\"row_heading level0 row1\" >5</th>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row1_col0\" class=\"data row1 col0\" >LogisticRegression</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row1_col1\" class=\"data row1 col1\" >0.845679</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row1_col2\" class=\"data row1 col2\" >0.760756</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce58bbce_0840_11eb_b896_acde48001122level0_row2\" class=\"row_heading level0 row2\" >7</th>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row2_col0\" class=\"data row2 col0\" >AdaBoostClassifier</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row2_col1\" class=\"data row2 col1\" >0.830753</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row2_col2\" class=\"data row2 col2\" >0.742353</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce58bbce_0840_11eb_b896_acde48001122level0_row3\" class=\"row_heading level0 row3\" >1</th>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row3_col0\" class=\"data row3 col0\" >KNeighborsClassifier</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row3_col1\" class=\"data row3 col1\" >0.775508</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row3_col2\" class=\"data row3 col2\" >0.73084</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce58bbce_0840_11eb_b896_acde48001122level0_row4\" class=\"row_heading level0 row4\" >6</th>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row4_col0\" class=\"data row4 col0\" >GradientBoostingClassifier</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row4_col1\" class=\"data row4 col1\" >0.788819</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row4_col2\" class=\"data row4 col2\" >0.72521</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce58bbce_0840_11eb_b896_acde48001122level0_row5\" class=\"row_heading level0 row5\" >2</th>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row5_col0\" class=\"data row5 col0\" >DecisionTreeClassifier</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row5_col1\" class=\"data row5 col1\" >1</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row5_col2\" class=\"data row5 col2\" >0.71084</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce58bbce_0840_11eb_b896_acde48001122level0_row6\" class=\"row_heading level0 row6\" >3</th>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row6_col0\" class=\"data row6 col0\" >RandomForestClassifier</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row6_col1\" class=\"data row6 col1\" >0.960688</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row6_col2\" class=\"data row6 col2\" >0.698992</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce58bbce_0840_11eb_b896_acde48001122level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row7_col0\" class=\"data row7 col0\" >ExtraTreesClassifier</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row7_col1\" class=\"data row7 col1\" >1</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row7_col2\" class=\"data row7 col2\" >0.698992</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce58bbce_0840_11eb_b896_acde48001122level0_row8\" class=\"row_heading level0 row8\" >4</th>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row8_col0\" class=\"data row8 col0\" >SVC</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row8_col1\" class=\"data row8 col1\" >0.511051</td>\n",
       "                        <td id=\"T_ce58bbce_0840_11eb_b896_acde48001122row8_col2\" class=\"data row8 col2\" >0.496807</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe07e3afa10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(accuracy_compare(x_train, target, models, cv))\n",
    "display(f1_compare(x_train, target, models, cv))\n",
    "display(precision_compare(x_train, target, models, cv))\n",
    "display(recall_compare(x_train, target, models, cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_model = VotingClassifier(\n",
    "    estimators=[('naive', naive),\n",
    "                (\"knn\", knn),\n",
    "                ('dtree', dtree),\n",
    "                ('rf', rf),\n",
    "                ('svc', svc),\n",
    "                ('lr', lr), \n",
    "                ('gradient', gradient), \n",
    "                ('ada', ada), \n",
    "                ('extra_dt', extra_dt)]\n",
    "    , voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristobalza/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cristobalza/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/cristobalza/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/cristobalza/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "voting_model.fit(x_train, target)\n",
    "submission = pd.DataFrame(index=passengers_ID_test)\n",
    "submission['Survived'] = voting_model.predict(x_test)\n",
    "submission.reset_index().to_csv('output/submission_no_tuning_soft.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_model = VotingClassifier(\n",
    "    estimators=[('naive', naive),\n",
    "                (\"knn\", knn),\n",
    "                ('dtree', dtree),\n",
    "                ('rf', rf),\n",
    "                ('svc', svc),\n",
    "                ('lr', lr), \n",
    "                ('gradient', gradient), \n",
    "                ('ada', ada), \n",
    "                ('extra_dt', extra_dt)]\n",
    "    , voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristobalza/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cristobalza/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/cristobalza/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/cristobalza/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "voting_model.fit(x_train, target)\n",
    "submission = pd.DataFrame(index=passengers_ID_test)\n",
    "submission['Survived'] = voting_model.predict(x_test)\n",
    "submission.reset_index().to_csv('output/submission_no_tuning_hard.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status(feature):\n",
    "    print('Processing', feature, ': ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_data():\n",
    "    # reading train data\n",
    "    train = pd.read_csv('./data/train.csv')\n",
    "    \n",
    "    # reading test data\n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "    # extracting and then removing the targets from the training data \n",
    "    targets = train.Survived\n",
    "    train.drop(['Survived'], 1, inplace=True)\n",
    "    \n",
    "\n",
    "    # merging train data and test data for future feature engineering\n",
    "    # we'll also remove the PassengerID since this is not an informative feature\n",
    "    combined = train.append(test)\n",
    "    combined.reset_index(inplace=True)\n",
    "    combined.drop(['index', 'PassengerId'], inplace=True, axis=1)\n",
    "    \n",
    "    return combined\n",
    "\n",
    "combined = get_combined_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 10)\n"
     ]
    }
   ],
   "source": [
    "print(combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ms', 'Miss', 'Mrs', 'Capt', 'Dr', 'Mr', 'Master', 'Jonkheer', 'Don', 'Lady', 'Major', 'Mlle', 'Col', 'Rev', 'Mme', 'the Countess', 'Sir'}\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/train.csv')\n",
    "titles = set()\n",
    "for name in data['Name']:\n",
    "    titles.add(name.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "print(titles)\n",
    "# set(['Sir', 'Major', 'the Countess', 'Don', 'Mlle', 'Capt', 'Dr', 'Lady', 'Rev', 'Mrs', 'Jonkheer', 'Master', 'Ms', 'Mr', 'Mme', 'Miss', 'Col'])\n",
    "\n",
    "Title_Dictionary = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Jonkheer\": \"Royalty\",\n",
    "    \"Don\": \"Royalty\",\n",
    "    \"Sir\" : \"Royalty\",\n",
    "    \"Dr\": \"Officer\",\n",
    "    \"Rev\": \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\" : \"Mr\",\n",
    "    \"Mrs\" : \"Mrs\",\n",
    "    \"Miss\" : \"Miss\",\n",
    "    \"Master\" : \"Master\",\n",
    "    \"Lady\" : \"Royalty\"\n",
    "}\n",
    "\n",
    "def get_titles():\n",
    "    # we extract the title from each name\n",
    "    combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "    \n",
    "    # a map of more aggregated title\n",
    "    # we map each title\n",
    "    combined['Title'] = combined.Title.map(Title_Dictionary)\n",
    "    status('Title')\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Title : ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass                                               Name     Sex   Age  \\\n",
       "0       3                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2       3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4       3                           Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked Title  \n",
       "0      1      0         A/5 21171   7.2500   NaN        S    Mr  \n",
       "1      1      0          PC 17599  71.2833   C85        C   Mrs  \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S  Miss  \n",
       "3      1      0            113803  53.1000  C123        S   Mrs  \n",
       "4      0      0            373450   8.0500   NaN        S    Mr  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = get_titles()\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pclass                          Name     Sex   Age  SibSp  Parch  \\\n",
       "1305       1  Oliva y Ocana, Dona. Fermina  female  39.0      0      0   \n",
       "\n",
       "        Ticket   Fare Cabin Embarked Title  \n",
       "1305  PC 17758  108.9  C105        C   NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[combined['Title'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "print(combined.iloc[:891].Age.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Title</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>Officer</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>Royalty</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>Miss</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Pclass    Title   Age\n",
       "0  female       1     Miss  30.0\n",
       "1  female       1      Mrs  40.0\n",
       "2  female       1  Officer  49.0\n",
       "3  female       1  Royalty  40.5\n",
       "4  female       2     Miss  24.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(combined.iloc[891:].Age.isnull().sum())\n",
    "# 86\n",
    "\n",
    "grouped_train = combined.iloc[:891].groupby(['Sex','Pclass','Title'])\n",
    "grouped_median_train = grouped_train.median()\n",
    "grouped_median_train = grouped_median_train.reset_index()[['Sex', 'Pclass', 'Title', 'Age']]\n",
    "\n",
    "grouped_median_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing age : ok\n"
     ]
    }
   ],
   "source": [
    "def fill_age(row):\n",
    "    condition = (\n",
    "        (grouped_median_train['Sex'] == row['Sex']) & \n",
    "        (grouped_median_train['Title'] == row['Title']) & \n",
    "        (grouped_median_train['Pclass'] == row['Pclass'])\n",
    "    ) \n",
    "    return grouped_median_train[condition]['Age'].values[0]\n",
    "\n",
    "\n",
    "def process_age():\n",
    "    global combined\n",
    "    # a function that fills the missing values of the Age variable\n",
    "    combined['Age'] = combined.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n",
    "    status('age')\n",
    "    return combined\n",
    "\n",
    "combined = process_age()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_names():\n",
    "    global combined\n",
    "    # we clean the Name variable\n",
    "    combined.drop('Name', axis=1, inplace=True)\n",
    "    \n",
    "    # encoding in dummy variable\n",
    "    titles_dummies = pd.get_dummies(combined['Title'], prefix='Title')\n",
    "    combined = pd.concat([combined, titles_dummies], axis=1)\n",
    "    \n",
    "    # removing the title variable\n",
    "    combined.drop('Title', axis=1, inplace=True)\n",
    "    \n",
    "    status('names')\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing names : ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch            Ticket     Fare Cabin  \\\n",
       "0       3    male  22.0      1      0         A/5 21171   7.2500   NaN   \n",
       "1       1  female  38.0      1      0          PC 17599  71.2833   C85   \n",
       "2       3  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN   \n",
       "3       1  female  35.0      1      0            113803  53.1000  C123   \n",
       "4       3    male  35.0      0      0            373450   8.0500   NaN   \n",
       "\n",
       "  Embarked  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Officer  \\\n",
       "0        S             0           0         1          0              0   \n",
       "1        C             0           0         0          1              0   \n",
       "2        S             0           1         0          0              0   \n",
       "3        S             0           0         0          1              0   \n",
       "4        S             0           0         1          0              0   \n",
       "\n",
       "   Title_Royalty  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = process_names()\n",
    "\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fares():\n",
    "    global combined\n",
    "    # there's one missing fare value - replacing it with the mean.\n",
    "    combined.Fare.fillna(combined.iloc[:891].Fare.mean(), inplace=True)\n",
    "    status('fare')\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fare : ok\n"
     ]
    }
   ],
   "source": [
    "combined = process_fares()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_embarked():\n",
    "    global combined\n",
    "    # two missing embarked values - filling them with the most frequent one in the train  set(S)\n",
    "    combined.Embarked.fillna('S', inplace=True)\n",
    "    # dummy encoding \n",
    "    embarked_dummies = pd.get_dummies(combined['Embarked'], prefix='Embarked')\n",
    "    combined = pd.concat([combined, embarked_dummies], axis=1)\n",
    "    combined.drop('Embarked', axis=1, inplace=True)\n",
    "    status('embarked')\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing embarked : ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch            Ticket     Fare Cabin  \\\n",
       "0       3    male  22.0      1      0         A/5 21171   7.2500   NaN   \n",
       "1       1  female  38.0      1      0          PC 17599  71.2833   C85   \n",
       "2       3  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN   \n",
       "3       1  female  35.0      1      0            113803  53.1000  C123   \n",
       "4       3    male  35.0      0      0            373450   8.0500   NaN   \n",
       "\n",
       "   Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Officer  \\\n",
       "0             0           0         1          0              0   \n",
       "1             0           0         0          1              0   \n",
       "2             0           1         0          0              0   \n",
       "3             0           0         0          1              0   \n",
       "4             0           0         1          0              0   \n",
       "\n",
       "   Title_Royalty  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0              0           0           0           1  \n",
       "1              0           1           0           0  \n",
       "2              0           0           0           1  \n",
       "3              0           0           0           1  \n",
       "4              0           0           0           1  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = process_embarked()\n",
    "\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C', 'U', 'A', 'B', 'E', 'G', 'F', 'D', 'T'}\n",
      "{'C', 'U', 'A', 'B', 'E', 'G', 'F', 'D'}\n"
     ]
    }
   ],
   "source": [
    "train_cabin, test_cabin = set(), set()\n",
    "\n",
    "for c in combined.iloc[:891]['Cabin']:\n",
    "    try:\n",
    "        train_cabin.add(c[0])\n",
    "    except:\n",
    "        train_cabin.add('U')\n",
    "        \n",
    "for c in combined.iloc[891:]['Cabin']:\n",
    "    try:\n",
    "        test_cabin.add(c[0])\n",
    "    except:\n",
    "        test_cabin.add('U')\n",
    "\n",
    "print(train_cabin)\n",
    "# set(['A', 'C', 'B', 'E', 'D', 'G', 'F', 'U', 'T'])\n",
    "\n",
    "print(test_cabin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cabin():\n",
    "    global combined    \n",
    "    # replacing missing cabins with U (for Uknown)\n",
    "    combined.Cabin.fillna('U', inplace=True)\n",
    "    \n",
    "    # mapping each Cabin value with the cabin letter\n",
    "    combined['Cabin'] = combined['Cabin'].map(lambda c: c[0])\n",
    "    \n",
    "    # dummy encoding ...\n",
    "    cabin_dummies = pd.get_dummies(combined['Cabin'], prefix='Cabin')    \n",
    "    combined = pd.concat([combined, cabin_dummies], axis=1)\n",
    "\n",
    "    combined.drop('Cabin', axis=1, inplace=True)\n",
    "    status('cabin')\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cabin : ok\n"
     ]
    }
   ],
   "source": [
    "combined = process_cabin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Cabin_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch            Ticket     Fare  \\\n",
       "0       3    male  22.0      1      0         A/5 21171   7.2500   \n",
       "1       1  female  38.0      1      0          PC 17599  71.2833   \n",
       "2       3  female  26.0      0      0  STON/O2. 3101282   7.9250   \n",
       "3       1  female  35.0      1      0            113803  53.1000   \n",
       "4       3    male  35.0      0      0            373450   8.0500   \n",
       "\n",
       "   Title_Master  Title_Miss  Title_Mr  ...  Embarked_S  Cabin_A  Cabin_B  \\\n",
       "0             0           0         1  ...           1        0        0   \n",
       "1             0           0         0  ...           0        0        0   \n",
       "2             0           1         0  ...           1        0        0   \n",
       "3             0           0         0  ...           1        0        0   \n",
       "4             0           0         1  ...           1        0        0   \n",
       "\n",
       "   Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_T  Cabin_U  \n",
       "0        0        0        0        0        0        0        1  \n",
       "1        1        0        0        0        0        0        0  \n",
       "2        0        0        0        0        0        0        1  \n",
       "3        1        0        0        0        0        0        0  \n",
       "4        0        0        0        0        0        0        1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sex():\n",
    "    global combined\n",
    "    # mapping string values to numerical one \n",
    "    combined['Sex'] = combined['Sex'].map({'male':1, 'female':0})\n",
    "    status('Sex')\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Sex : ok\n"
     ]
    }
   ],
   "source": [
    "combined = process_sex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pclass():\n",
    "    \n",
    "    global combined\n",
    "    # encoding into 3 categories:\n",
    "    pclass_dummies = pd.get_dummies(combined['Pclass'], prefix=\"Pclass\")\n",
    "    \n",
    "    # adding dummy variable\n",
    "    combined = pd.concat([combined, pclass_dummies],axis=1)\n",
    "    \n",
    "    # removing \"Pclass\"\n",
    "    combined.drop('Pclass',axis=1,inplace=True)\n",
    "    \n",
    "    status('Pclass')\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Pclass : ok\n"
     ]
    }
   ],
   "source": [
    "combined = process_pclass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'filter' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-042d7a151ac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_ticket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-74-042d7a151ac2>\u001b[0m in \u001b[0;36mprocess_ticket\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Extracting dummy variables from tickets:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mcombined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticket'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticket'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleanTicket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mtickets_dummies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticket'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Ticket'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtickets_dummies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   3823\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3824\u001b[0m         \"\"\"\n\u001b[0;32m-> 3825\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3826\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-042d7a151ac2>\u001b[0m in \u001b[0;36mcleanTicket\u001b[0;34m(ticket)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mticket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mticket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticket\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mticket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'filter' has no len()"
     ]
    }
   ],
   "source": [
    "def cleanTicket(ticket):\n",
    "    ticket = ticket.replace('.', '')\n",
    "    ticket = ticket.replace('/', '')\n",
    "    ticket = ticket.split()\n",
    "    ticket = map(lambda t : t.strip(), ticket)\n",
    "    ticket = list(filter(lambda t : not t.isdigit(), ticket))\n",
    "    if len(ticket) > 0:\n",
    "        return ticket[0]\n",
    "    else: \n",
    "        return 'XXX'\n",
    "\n",
    "tickets = set()\n",
    "for t in combined['Ticket']:\n",
    "    tickets.add(cleanTicket(t))\n",
    "\n",
    "print(len(tickets))\n",
    "#37\n",
    "\n",
    "\n",
    "def process_ticket():\n",
    "    \n",
    "    global combined\n",
    "    \n",
    "    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n",
    "    def cleanTicket(ticket):\n",
    "        ticket = ticket.replace('.','')\n",
    "        ticket = ticket.replace('/','')\n",
    "        ticket = ticket.split()\n",
    "        ticket = map(lambda t : t.strip(), ticket)\n",
    "        ticket = filter(lambda t : not t.isdigit(), ticket)\n",
    "        if len(ticket) > 0:\n",
    "            return ticket[0]\n",
    "        else: \n",
    "            return 'XXX'\n",
    "    \n",
    "\n",
    "    # Extracting dummy variables from tickets:\n",
    "\n",
    "    combined['Ticket'] = combined['Ticket'].map(cleanTicket)\n",
    "    tickets_dummies = pd.get_dummies(combined['Ticket'], prefix='Ticket')\n",
    "    combined = pd.concat([combined, tickets_dummies], axis=1)\n",
    "    combined.drop('Ticket', inplace=True, axis=1)\n",
    "\n",
    "    status('Ticket')\n",
    "    return combined\n",
    "\n",
    "combined = process_ticket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
